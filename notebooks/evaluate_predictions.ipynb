{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model's predictions against gold labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:\n",
      "         elin    lena   oscar     agg   model  mean_human\n",
      "elin   100.00   60.86   61.71   74.86   13.43       61.29\n",
      "lena    60.86  100.00   66.86   81.71   11.43       63.86\n",
      "oscar   61.71   66.86  100.00   84.00    9.43       64.29\n",
      "agg     74.86   81.71   84.00  100.00   12.57       80.19\n",
      "model   13.43   11.43    9.43   12.57  100.00       11.43\n",
      "\n",
      "Humans' mean accuracy: 67.40\n",
      "Model's mean accuracy: 11.71\n",
      "Diff in mean accuracy: 55.69\n",
      "\n",
      "KAPPA:\n",
      "         elin    lena   oscar     agg   model  mean_human\n",
      "elin   100.00   48.68   49.93   67.28   -0.08       49.30\n",
      "lena    48.68  100.00   53.37   75.09    0.10       51.02\n",
      "oscar   49.93   53.37  100.00   78.19    0.08       51.65\n",
      "agg     67.28   75.09   78.19  100.00    0.16       73.52\n",
      "model   -0.08    0.10    0.08    0.16  100.00        0.03\n",
      "\n",
      "Humans' mean kappa: 56.37\n",
      "Model's mean kappa: 0.06\n",
      "Diff in mean kappa: 56.31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "# read inference results\n",
    "df_predictions = pd.read_csv('../results/pappa_dim1_flan-t5-small_0106_181636.pre.csv', sep=';')\n",
    "\n",
    "# retrieve columns starting with \"gold\" and their \"names\"\n",
    "gold_labels = df_predictions.filter(regex='^gold', axis=1)\n",
    "gold_names = [col.split('gold_')[-1] for col in gold_labels.columns]\n",
    "human_names = [name for name in gold_names if 'agg' not in name]\n",
    "\n",
    "# define tables where to store results\n",
    "df_kappa = pd.DataFrame(columns=gold_names+['model'], index=gold_names+['model']).fillna(1.0)\n",
    "df_accuracy = pd.DataFrame(columns=gold_names+['model'], index=gold_names+['model']).fillna(1.0)\n",
    "\n",
    "\n",
    "for i, col in enumerate(gold_labels.columns):\n",
    "    # compare agreement with gold labels\n",
    "    kappa = cohen_kappa_score(df_predictions['prediction'].astype(str), gold_labels[col].astype(str))\n",
    "    accuracy = accuracy_score(df_predictions['prediction'].astype(str), gold_labels[col].astype(str))\n",
    "    # store results\n",
    "    df_kappa.loc['model', gold_names[i]] = df_kappa.loc[gold_names[i], 'model'] = kappa\n",
    "    df_accuracy.loc['model', gold_names[i]] = df_accuracy.loc[gold_names[i], 'model'] = accuracy\n",
    "\n",
    "    for j, col2 in enumerate(gold_labels.columns):\n",
    "        if i < j:\n",
    "            # compare agreement of gold labels with each other\n",
    "            kappa = cohen_kappa_score(gold_labels[col].astype(str), gold_labels[col2].astype(str))\n",
    "            accuracy = accuracy_score(gold_labels[col].astype(str), gold_labels[col2].astype(str))\n",
    "            # store results\n",
    "            df_kappa.loc[gold_names[i], gold_names[j]] = df_kappa.loc[gold_names[j], gold_names[i]] = kappa\n",
    "            df_accuracy.loc[gold_names[i], gold_names[j]] = df_accuracy.loc[gold_names[j], gold_names[i]] = accuracy\n",
    "\n",
    "# compute average agreement between humans\n",
    "df_kappa['mean_human'] = df_kappa[human_names].mean(axis=1)\n",
    "df_accuracy['mean_human'] = df_accuracy[human_names].mean(axis=1)\n",
    "for name in human_names:\n",
    "    # correct for humans fully agreeing with themselves\n",
    "    df_kappa.mean_human[name] = (df_kappa[human_names].loc[name].sum() - 1.0) / (len(human_names) - 1.0)\n",
    "    df_accuracy.mean_human[name] = (df_accuracy[human_names].loc[name].sum() - 1.0) / (len(human_names) - 1.0)\n",
    "\n",
    "print('ACCURACY:')\n",
    "print(df_accuracy.round(4)*100)\n",
    "print()\n",
    "print(f\"Humans' mean accuracy: {100*df_accuracy.mean_human[:-1].mean():.2f}\")\n",
    "print(f\"Model's mean accuracy: {100*df_accuracy.model[:-1].mean():.2f}\")\n",
    "print(f'Diff in mean accuracy: {100*(df_accuracy.mean_human[:-1].mean() - df_accuracy.model[:-1].mean()):.2f}')\n",
    "print()\n",
    "print('KAPPA:')\n",
    "print(df_kappa.round(4)*100)\n",
    "print()\n",
    "print(f\"Humans' mean kappa: {100*df_kappa.mean_human[:-1].mean():.2f}\")\n",
    "print(f\"Model's mean kappa: {100*df_kappa.model[:-1].mean():.2f}\")\n",
    "print(f'Diff in mean kappa: {100*(df_kappa.mean_human[:-1].mean() - df_kappa.model[:-1].mean()):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humans' mean accuracy: 67.40\n",
      "Model's mean accuracy: 0.00\n",
      "Diff in mean accuracy: 67.40\n",
      "Model's mean accuracy: 0.00\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from Dirk's evaluation of GPT:\n",
    "\n",
    "````python\n",
    "dim1\n",
    "350\n",
    "RAW:\n",
    "               elin      lena     oscar  aggregate       GPT  mean_human\n",
    "elin       1.000000  0.608571  0.617143   0.748571  0.494286    0.612857\n",
    "lena       0.608571  1.000000  0.668571   0.817143  0.545714    0.638571\n",
    "oscar      0.617143  0.668571  1.000000   0.840000  0.528571    0.642857\n",
    "aggregate  0.748571  0.817143  0.840000   1.000000  0.548571    0.801905\n",
    "GPT        0.494286  0.545714  0.528571   0.548571  1.000000    0.522857\n",
    "KAPPA:\n",
    "               elin      lena     oscar  aggregate       GPT  mean_human\n",
    "elin       1.000000  0.486754  0.499290   0.672779  0.354546    0.493022\n",
    "lena       0.486754  1.000000  0.533719   0.750879  0.388609    0.510237\n",
    "oscar      0.499290  0.533719  1.000000   0.781927  0.364316    0.516505\n",
    "aggregate  0.672779  0.750879  0.781927   1.000000  0.406302    0.735195\n",
    "GPT        0.354546  0.388609  0.364316   0.406302  1.000000    0.369157\n",
    "\n",
    "dim2\n",
    "225\n",
    "RAW:\n",
    "               elin      lena     oscar  aggregate       GPT  mean_human\n",
    "elin       1.000000  0.613333  0.631111   0.835556  0.591111    0.622222\n",
    "lena       0.613333  1.000000  0.706667   0.511111  0.760000    0.660000\n",
    "oscar      0.631111  0.706667  1.000000   0.795556  0.577778    0.668889\n",
    "aggregate  0.835556  0.511111  0.795556   1.000000  0.462222    0.714074\n",
    "GPT        0.591111  0.760000  0.577778   0.462222  1.000000    0.642963\n",
    "KAPPA:\n",
    "               elin      lena     oscar  aggregate       GPT  mean_human\n",
    "elin       1.000000  0.014797  0.194175   0.677288  0.110251    0.104486\n",
    "lena       0.014797  1.000000  0.181818   0.081155  0.145570    0.098308\n",
    "oscar      0.194175  0.181818  1.000000   0.601156  0.030612    0.187996\n",
    "aggregate  0.677288  0.081155  0.601156   1.000000  0.036624    0.453200\n",
    "GPT        0.110251  0.145570  0.030612   0.036624  1.000000    0.095478\n",
    "\n",
    "dim3\n",
    "225\n",
    "RAW:\n",
    "               elin      lena     oscar  aggregate       GPT  mean_human\n",
    "elin       1.000000  0.746667  0.857778   1.000000  0.746667    0.802222\n",
    "lena       0.746667  1.000000  0.808889   0.746667  0.702222    0.777778\n",
    "oscar      0.857778  0.808889  1.000000   0.857778  0.737778    0.833333\n",
    "aggregate  1.000000  0.746667  0.857778   1.000000  0.746667    0.868148\n",
    "GPT        0.746667  0.702222  0.737778   0.746667  1.000000    0.728889\n",
    "KAPPA:\n",
    "               elin      lena     oscar  aggregate       GPT  mean_human\n",
    "elin       1.000000  0.312590  0.629630   1.000000  0.468812    0.471110\n",
    "lena       0.312590  1.000000  0.354354   0.312590  0.303245    0.333472\n",
    "oscar      0.629630  0.354354  1.000000   0.629630  0.405242    0.491992\n",
    "aggregate  1.000000  0.312590  0.629630   1.000000  0.468812    0.647407\n",
    "GPT        0.468812  0.303245  0.405242   0.468812  1.000000    0.392433\n",
    "\n",
    "\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
