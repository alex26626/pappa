{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b8deabf",
   "metadata": {},
   "source": [
    "# Evaluate automatic coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702fec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 5)\n",
      "(350, 5)\n",
      "(350, 5)\n",
      "(350, 5)\n",
      "333163\n",
      "333163\n",
      "333163\n",
      "333163\n",
      "350\n",
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llupo/miniconda3/envs/mentalenv/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/llupo/miniconda3/envs/mentalenv/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Users/llupo/miniconda3/envs/mentalenv/lib/python3.10/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# get each coding\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "\n",
    "limit = 350 # WHY LIMIT???\n",
    "clean_na_dim23 = False\n",
    "\n",
    "# Load annotations\n",
    "df_gpt = pd.read_excel('../data/sample_for_check_GPT3.xlsx').fillna('NA')[:limit]\n",
    "df_elin = pd.read_excel('../data/human_annotation/ELINsample_for_check_human.xlsx').fillna('NA')[:limit]\n",
    "df_lena = pd.read_excel('../data/human_annotation/Lenasample_for_check_human.xlsx').fillna('NA')[:limit]\n",
    "df_oscar = pd.read_excel('../data/human_annotation/Oscarsample_for_check_human.xlsx').fillna('NA')[:limit]\n",
    "masks = dict()\n",
    "\n",
    "# Output a .csv / .xlxs table for each dim, cleaning dim2 and dim3 from NA\n",
    "for dim in 'dim1 dim2 dim3'.split():\n",
    "\n",
    "    names = ['elin', 'lena', 'oscar']\n",
    "\n",
    "    data = {'elin': df_elin[dim], 'lena': df_lena[dim], 'oscar': df_oscar[dim]}\n",
    "    out = pd.DataFrame(data=data)\n",
    "    \n",
    "    # Keep only dim2 and dim3 examples where all the annotators provided a label\n",
    "    # dim1 is excluded because NA is a possible label in that category\n",
    "    if dim in {'dim2', 'dim3'}:\n",
    "        if clean_na_dim23:\n",
    "            masks[dim] = (out.elin != 'NA') & (out.lena!=\"NA\") & (out.oscar!=\"NA\") \n",
    "        else:\n",
    "            masks[dim] = out.elin.notnull() # all values are True\n",
    "        out2 = out[masks[dim]]\n",
    "    else:\n",
    "        out2 = out\n",
    "    \n",
    "    # Write table to file\n",
    "    #out2.to_excel('../data/human_annotation/{}.xlsx'.format(dim), index=None)\n",
    "    #out2.to_csv('../data/human_annotation/{}'.format(dim), index=None, header=None)\n",
    "\n",
    "print(df_elin.shape)\n",
    "print(df_oscar.shape)\n",
    "print(df_lena.shape)\n",
    "print(df_gpt.shape)\n",
    "print(df_elin.tail(1).iloc[0,0])\n",
    "print(df_oscar.tail(1).iloc[0,0])\n",
    "print(df_lena.tail(1).iloc[0,0])\n",
    "print(df_gpt.tail(1).iloc[0,0])\n",
    "for dim in 'dim2 dim3'.split():\n",
    "    print(masks[dim].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20fba08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: ./data/human_annotation/: read: Is a directory\n",
      "     350 ./data/human_annotation/dim1.prediction.csv\n",
      "     350 ./data/human_annotation/dim2.prediction.csv\n",
      "     350 ./data/human_annotation/dim3.prediction.csv\n",
      "    1050 total\n"
     ]
    }
   ],
   "source": [
    "# ! wc -l ./data/human_annotation/${i} ./data/human_annotation/*csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e73e1df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file '../data/GPT/human_annotation/dim1.csv'\n",
      "....................100\n",
      "....................200\n",
      "....................300\n",
      ".........\n",
      "stats:\n",
      "\t350 instances,\n",
      "\t6 labels [PASSIVE, NA, ACTIVE_POS_OTHER, ACTIVE_NEG, ACTIVE_POS_CHALLENGING, ACTIVE_POS_CARING],\n",
      "\t3 annotators\n",
      "\n",
      "Running Variational Bayes EM training with the following settings:\n",
      "\t50 iterations\n",
      "\t10 restarts\n",
      "\tsmoothing = 0.0016666666666666668\n",
      "\talpha = 0.5\n",
      "\tbeta = 0.5\n",
      "\n",
      "============\n",
      "Restart 1\n",
      "============\n",
      "initial log marginal likelihood = -1555.6882106001829\n",
      "final log marginal likelihood = -1351.0009273885416\n",
      "\n",
      "============\n",
      "Restart 2\n",
      "============\n",
      "initial log marginal likelihood = -1553.1490471943941\n",
      "final log marginal likelihood = -1351.0009277253812\n",
      "\n",
      "============\n",
      "Restart 3\n",
      "============\n",
      "initial log marginal likelihood = -1572.0079877178498\n",
      "final log marginal likelihood = -1351.0009276184364\n",
      "\n",
      "============\n",
      "Restart 4\n",
      "============\n",
      "initial log marginal likelihood = -1542.5678174738118\n",
      "final log marginal likelihood = -1351.0009269094794\n",
      "\n",
      "============\n",
      "Restart 5\n",
      "============\n",
      "initial log marginal likelihood = -1522.559650468198\n",
      "final log marginal likelihood = -1351.0009291941885\n",
      "\n",
      "============\n",
      "Restart 6\n",
      "============\n",
      "initial log marginal likelihood = -1539.8938086832527\n",
      "final log marginal likelihood = -1351.0009279326193\n",
      "\n",
      "============\n",
      "Restart 7\n",
      "============\n",
      "initial log marginal likelihood = -1547.517322652772\n",
      "final log marginal likelihood = -1351.0009261685561\n",
      "\n",
      "============\n",
      "Restart 8\n",
      "============\n",
      "initial log marginal likelihood = -1545.8200248611531\n",
      "final log marginal likelihood = -1351.0009276196924\n",
      "\n",
      "============\n",
      "Restart 9\n",
      "============\n",
      "initial log marginal likelihood = -1523.5602253423754\n",
      "final log marginal likelihood = -1351.0009281302052\n",
      "\n",
      "============\n",
      "Restart 10\n",
      "============\n",
      "initial log marginal likelihood = -1539.0940926606597\n",
      "final log marginal likelihood = -1351.0009284231116\n",
      "\n",
      "Training completed in 0.107sec\n",
      "Best model came from random restart number 7 (log marginal likelihood: -1351.0009261685561)\n",
      "writing to file '../data/GPT/human_annotation/dim1.prediction'...done\n",
      "writing to file '../data/GPT/human_annotation/dim1.competence'...done\n",
      "Reading CSV file '../data/GPT/human_annotation/dim2.csv'\n",
      "....................100\n",
      "....................200\n",
      "....\n",
      "stats:\n",
      "\t225 instances,\n",
      "\t2 labels [EXPLICIT, IMPLICIT],\n",
      "\t3 annotators\n",
      "\n",
      "Running Variational Bayes EM training with the following settings:\n",
      "\t50 iterations\n",
      "\t10 restarts\n",
      "\tsmoothing = 0.005\n",
      "\talpha = 0.5\n",
      "\tbeta = 0.5\n",
      "\n",
      "============\n",
      "Restart 1\n",
      "============\n",
      "initial log marginal likelihood = -436.5779630006665\n",
      "final log marginal likelihood = -352.5599264985357\n",
      "\n",
      "============\n",
      "Restart 2\n",
      "============\n",
      "initial log marginal likelihood = -447.94878245355636\n",
      "final log marginal likelihood = -352.4972826758624\n",
      "\n",
      "============\n",
      "Restart 3\n",
      "============\n",
      "initial log marginal likelihood = -451.40533597907813\n",
      "final log marginal likelihood = -352.5546179592183\n",
      "\n",
      "============\n",
      "Restart 4\n",
      "============\n",
      "initial log marginal likelihood = -437.78305180765466\n",
      "final log marginal likelihood = -352.6026818859676\n",
      "\n",
      "============\n",
      "Restart 5\n",
      "============\n",
      "initial log marginal likelihood = -449.7419532403094\n",
      "final log marginal likelihood = -352.55401863410253\n",
      "\n",
      "============\n",
      "Restart 6\n",
      "============\n",
      "initial log marginal likelihood = -450.61612127950593\n",
      "final log marginal likelihood = -352.53355260639086\n",
      "\n",
      "============\n",
      "Restart 7\n",
      "============\n",
      "initial log marginal likelihood = -446.8054332029819\n",
      "final log marginal likelihood = -352.5924938700264\n",
      "\n",
      "============\n",
      "Restart 8\n",
      "============\n",
      "initial log marginal likelihood = -448.5412552357834\n",
      "final log marginal likelihood = -352.6267410052999\n",
      "\n",
      "============\n",
      "Restart 9\n",
      "============\n",
      "initial log marginal likelihood = -435.1739258768024\n",
      "final log marginal likelihood = -352.5827765736858\n",
      "\n",
      "============\n",
      "Restart 10\n",
      "============\n",
      "initial log marginal likelihood = -452.5323824296189\n",
      "final log marginal likelihood = -352.53147222312305\n",
      "\n",
      "Training completed in 0.045sec\n",
      "Best model came from random restart number 2 (log marginal likelihood: -352.4972826758624)\n",
      "writing to file '../data/GPT/human_annotation/dim2.prediction'...done\n",
      "writing to file '../data/GPT/human_annotation/dim2.competence'...done\n",
      "Reading CSV file '../data/GPT/human_annotation/dim3.csv'\n",
      "....................100\n",
      "....................200\n",
      "....\n",
      "stats:\n",
      "\t225 instances,\n",
      "\t2 labels [IDEAL, DESCRIPTIVE],\n",
      "\t3 annotators\n",
      "\n",
      "Running Variational Bayes EM training with the following settings:\n",
      "\t50 iterations\n",
      "\t10 restarts\n",
      "\tsmoothing = 0.005\n",
      "\talpha = 0.5\n",
      "\tbeta = 0.5\n",
      "\n",
      "============\n",
      "Restart 1\n",
      "============\n",
      "initial log marginal likelihood = -391.57970687150214\n",
      "final log marginal likelihood = -314.89867473554347\n",
      "\n",
      "============\n",
      "Restart 2\n",
      "============\n",
      "initial log marginal likelihood = -392.7235532308338\n",
      "final log marginal likelihood = -314.8990229874795\n",
      "\n",
      "============\n",
      "Restart 3\n",
      "============\n",
      "initial log marginal likelihood = -396.9754617317548\n",
      "final log marginal likelihood = -314.90723157438674\n",
      "\n",
      "============\n",
      "Restart 4\n",
      "============\n",
      "initial log marginal likelihood = -390.2287441412571\n",
      "final log marginal likelihood = -314.90333510226077\n",
      "\n",
      "============\n",
      "Restart 5\n",
      "============\n",
      "initial log marginal likelihood = -397.22982929447136\n",
      "final log marginal likelihood = -314.9032384305589\n",
      "\n",
      "============\n",
      "Restart 6\n",
      "============\n",
      "initial log marginal likelihood = -395.2897708058478\n",
      "final log marginal likelihood = -314.9099718865849\n",
      "\n",
      "============\n",
      "Restart 7\n",
      "============\n",
      "initial log marginal likelihood = -407.6555496294826\n",
      "final log marginal likelihood = -314.91020281869527\n",
      "\n",
      "============\n",
      "Restart 8\n",
      "============\n",
      "initial log marginal likelihood = -391.3460642154995\n",
      "final log marginal likelihood = -314.9052483562302\n",
      "\n",
      "============\n",
      "Restart 9\n",
      "============\n",
      "initial log marginal likelihood = -399.0303906562092\n",
      "final log marginal likelihood = -314.8982140010825\n",
      "\n",
      "============\n",
      "Restart 10\n",
      "============\n",
      "initial log marginal likelihood = -383.1188418514682\n",
      "final log marginal likelihood = -314.8986503088548\n",
      "\n",
      "Training completed in 0.049sec\n",
      "Best model came from random restart number 9 (log marginal likelihood: -314.8982140010825)\n",
      "writing to file '../data/GPT/human_annotation/dim3.prediction'...done\n",
      "writing to file '../data/GPT/human_annotation/dim3.competence'...done\n"
     ]
    }
   ],
   "source": [
    "# ! /Users/dirkhovy/Dropbox/tools/MACE/MACE --prefix ../data/GPT/human_annotation/dim1 ../data/GPT/human_annotation/dim1.csv\n",
    "# ! /Users/dirkhovy/Dropbox/tools/MACE/MACE --prefix ../data/GPT/human_annotation/dim2 ../data/GPT/human_annotation/dim2.csv\n",
    "# ! /Users/dirkhovy/Dropbox/tools/MACE/MACE --prefix ../data/GPT/human_annotation/dim3 ../data/GPT/human_annotation/dim3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "794a0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim1\n",
      "elin:aggregate, kappa=0.67, agreement=0.75\n",
      "lena:aggregate, kappa=0.75, agreement=0.82\n",
      "oscar:aggregate, kappa=0.78, agreement=0.84\n",
      "aggregate:GPT, kappa=0.41, agreement=0.55\n",
      "RAW:\n",
      "               elin      lena     oscar  aggregate       GPT  mean_human\n",
      "elin       1.000000  0.608571  0.617143   0.748571  0.494286    0.612857\n",
      "lena       0.608571  1.000000  0.668571   0.817143  0.545714    0.638571\n",
      "oscar      0.617143  0.668571  1.000000   0.840000  0.528571    0.642857\n",
      "aggregate  0.748571  0.817143  0.840000   1.000000  0.548571    0.801905\n",
      "GPT        0.494286  0.545714  0.528571   0.548571  1.000000    0.522857\n",
      "KAPPA:\n",
      "               elin      lena     oscar  aggregate       GPT  mean_human\n",
      "elin       1.000000  0.486754  0.499290   0.672779  0.354546    0.493022\n",
      "lena       0.486754  1.000000  0.533719   0.750879  0.388609    0.510237\n",
      "oscar      0.499290  0.533719  1.000000   0.781927  0.364316    0.516505\n",
      "aggregate  0.672779  0.750879  0.781927   1.000000  0.406302    0.735195\n",
      "GPT        0.354546  0.388609  0.364316   0.406302  1.000000    0.369157\n",
      "\n",
      "dim2\n",
      "elin:aggregate, kappa=0.95, agreement=0.97\n",
      "lena:aggregate, kappa=0.31, agreement=0.57\n",
      "oscar:aggregate, kappa=0.36, agreement=0.59\n",
      "aggregate:GPT, kappa=0.20, agreement=0.50\n",
      "RAW:\n",
      "               elin      lena     oscar  aggregate       GPT  mean_human\n",
      "elin       1.000000  0.540000  0.557143   0.965714  0.505714    0.548571\n",
      "lena       0.540000  1.000000  0.625714   0.574286  0.682857    0.582857\n",
      "oscar      0.557143  0.625714  1.000000   0.591429  0.540000    0.591429\n",
      "aggregate  0.965714  0.574286  0.591429   1.000000  0.502857    0.710476\n",
      "GPT        0.505714  0.682857  0.540000   0.502857  1.000000    0.576190\n",
      "KAPPA:\n",
      "               elin      lena     oscar  aggregate       GPT  mean_human\n",
      "elin       1.000000  0.235455  0.299421   0.947616  0.186823    0.267438\n",
      "lena       0.235455  1.000000  0.295612   0.310796  0.259393    0.265534\n",
      "oscar      0.299421  0.295612  1.000000   0.362388  0.152937    0.297517\n",
      "aggregate  0.947616  0.310796  0.362388   1.000000  0.201217    0.540267\n",
      "GPT        0.186823  0.259393  0.152937   0.201217  1.000000    0.199718\n",
      "\n",
      "dim3\n",
      "elin:aggregate, kappa=0.97, agreement=0.98\n",
      "lena:aggregate, kappa=0.38, agreement=0.64\n",
      "oscar:aggregate, kappa=0.52, agreement=0.72\n",
      "aggregate:GPT, kappa=0.39, agreement=0.63\n",
      "RAW:\n",
      "               elin      lena     oscar  aggregate       GPT  mean_human\n",
      "elin       1.000000  0.625714  0.705714   0.982857  0.631429    0.665714\n",
      "lena       0.625714  1.000000  0.717143   0.642857  0.657143    0.671429\n",
      "oscar      0.705714  0.717143  1.000000   0.722857  0.674286    0.711429\n",
      "aggregate  0.982857  0.642857  0.722857   1.000000  0.631429    0.782857\n",
      "GPT        0.631429  0.657143  0.674286   0.631429  1.000000    0.654286\n",
      "KAPPA:\n",
      "               elin      lena     oscar  aggregate       GPT  mean_human\n",
      "elin       1.000000  0.344700  0.488188   0.972561  0.381998    0.416444\n",
      "lena       0.344700  1.000000  0.395204   0.383134  0.328011    0.369952\n",
      "oscar      0.488188  0.395204  1.000000   0.524050  0.370911    0.441696\n",
      "aggregate  0.972561  0.383134  0.524050   1.000000  0.388443    0.626582\n",
      "GPT        0.381998  0.328011  0.370911   0.388443  1.000000    0.360306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def adapt_to_dim1_mode(dim1_mode, labels):\n",
    "        if dim1_mode == 'binary':\n",
    "            labels = [x[:3] for x in labels]\n",
    "        elif dim1_mode == 'reduced':\n",
    "            labels = [x[:10] for x in labels]\n",
    "        return labels\n",
    "\n",
    "dim1_mode = '' #binary/reduced\n",
    "\n",
    "for dim in 'dim1 dim2 dim3'.split():\n",
    "    print(dim)\n",
    "\n",
    "    # read GPT labels\n",
    "    gpt_label = df_gpt[dim].values\n",
    "    # adapt to reduced and binary dim1\n",
    "    if dim == 'dim1':\n",
    "        gpt_label = adapt_to_dim1_mode(dim1_mode, gpt_label)\n",
    "    # account for excluded items\n",
    "    else:    \n",
    "        gpt_label = df_gpt[dim][masks[dim]].values\n",
    "\n",
    "    # read aggregated human labels\n",
    "    with open('../data/human_annotation/{}.prediction'.format(dim)) as dimagg:\n",
    "        dim_gpt_agg = [x.strip() for x in dimagg.readlines()]\n",
    "    # adapt to reduced and binary dim1\n",
    "    if dim == 'dim1':\n",
    "        dim_gpt_agg = adapt_to_dim1_mode(dim1_mode, dim_gpt_agg)\n",
    "  \n",
    "    # create tables to store agreement outcomes\n",
    "    conf_kappa = pd.DataFrame(columns=names+['aggregate', 'GPT'], index=names+['aggregate', 'GPT']).fillna(1.0)\n",
    "    conf_raw = pd.DataFrame(columns=names+['aggregate', 'GPT'], index=names+['aggregate', 'GPT']).fillna(1.0)\n",
    "\n",
    "    # read human' labels and compare\n",
    "    human = pd.read_excel('../data/human_annotation/{}.xlsx'.format(dim)).fillna('NA')\n",
    "    for i, name1 in enumerate(names):\n",
    "        label1 = human[name1].values\n",
    "        # adapt to reduced and binary dim1\n",
    "        if dim == 'dim1':\n",
    "            label1 = adapt_to_dim1_mode(dim1_mode, label1)\n",
    "        \n",
    "        # compare name's label with GPT\n",
    "        ck = cohen_kappa_score(label1, gpt_label)\n",
    "        agg = accuracy_score(label1, gpt_label)\n",
    "        \n",
    "        for j, name2 in enumerate(names[i+1:]):\n",
    "            label2 = human[name2].values\n",
    "            # adapt to reduced and binary dim1\n",
    "            if dim == 'dim1':\n",
    "                label2 = adapt_to_dim1_mode(dim1_mode, label2)\n",
    "                    \n",
    "            if name1 != name2:\n",
    "                ck1 = cohen_kappa_score(label1, label2)\n",
    "                agg1 = accuracy_score(label1, label2)\n",
    "                conf_kappa[name1][name2] = ck1\n",
    "                conf_raw[name1][name2] = agg1\n",
    "                conf_kappa[name2][name1] = ck1\n",
    "                conf_raw[name2][name1] = agg1\n",
    "                \n",
    "        conf_kappa['GPT'][name1] = ck\n",
    "        conf_raw['GPT'][name1] = agg\n",
    "        conf_kappa[name1]['GPT'] = ck\n",
    "        conf_raw[name1]['GPT'] = agg\n",
    "        ck_label_agg = cohen_kappa_score(dim_gpt_agg, label1)\n",
    "        agg_label_agg = accuracy_score(dim_gpt_agg, label1)\n",
    "        \n",
    "        # print('{}:aggregate, kappa={:.2f}, agreement={:.2f}'.format(name1, ck_label_agg, agg_label_agg))\n",
    "        \n",
    "        conf_kappa[name1]['aggregate'] = ck_label_agg\n",
    "        conf_raw[name1]['aggregate'] = agg_label_agg\n",
    "        conf_kappa['aggregate'][name1] = ck_label_agg\n",
    "        conf_raw['aggregate'][name1] = agg_label_agg\n",
    "\n",
    "    ck_agg = cohen_kappa_score(dim_gpt_agg, gpt_label)\n",
    "    agg_agg = accuracy_score(dim_gpt_agg, gpt_label)\n",
    "    \n",
    "    # ßprint('aggregate:GPT, kappa={:.2f}, agreement={:.2f}'.format(ck_agg, agg_agg))\n",
    "    \n",
    "    conf_kappa['GPT']['aggregate'] = ck_agg\n",
    "    conf_raw['GPT']['aggregate'] = agg_agg\n",
    "    conf_kappa['aggregate']['GPT'] = ck_agg\n",
    "    conf_raw['aggregate']['GPT'] = agg_agg\n",
    "    \n",
    "    conf_kappa['mean_human'] = conf_kappa[names].mean(axis=1)\n",
    "    conf_raw['mean_human'] = conf_raw[names].mean(axis=1)\n",
    "    for name in names:\n",
    "        conf_kappa.mean_human[name] = (conf_kappa[names].loc[name].sum() - 1.0) / 2\n",
    "        conf_raw.mean_human[name] = (conf_raw[names].loc[name].sum() - 1.0) / 2\n",
    "        \n",
    "    print('RAW:')\n",
    "    print(conf_raw)\n",
    "    print('KAPPA:')\n",
    "    print(conf_kappa)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649cc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
